# FeatherTrace 云端识别与分离部署方案

## 1. 架构设计

### 1.1 整体架构

```
┌─────────────────────────────────────────────────────────────────┐
│                         FeatherTrace                             │
├─────────────────────────────────────────────────────────────────┤
│  Web UI                    Pipeline                             │
│  ├── 照片浏览              ├── SmartScanner                      │
│  ├── 标签纠正              ├── BirdDetector (YOLO)               │
│  ├── 任务管理              ├── ImageProcessor                    │
│  └── 设置面板              └── BatchDispatcher ──────────────────┼──► ┌─────────────────┐
│                              │                                   │    │  识别服务集群   │
│                              └──► REST API 调用 ───────────────────► ├─────────────────┤
│                                         │                        │  │ LocalBioCLIP    │
│                                         │                        │  │ HuggingFace     │
│                                         ▼                        │  │ ModelScope      │
│                              ┌──────────────────┐                │  │ Aliyun          │
│                              │  Batch API       │                │  │ Custom API      │
│                              │  /api/recognize  │                └─────────────────┘
                              └──────────────────┘
```

### 1.2 识别服务抽象层

```
src/recognition/
├── base.py                    # BirdRecognizer 抽象基类
├── local.py                   # 本地 BioCLIP (保留)
├── cloud/                     # 云平台识别
│   ├── __init__.py
│   ├── huggingface.py         # HuggingFace Inference API
│   ├── modelscope.py          # 魔搭社区 API
│   ├── aliyun.py              # 阿里云视觉智能
│   ├── baidu.py               # 百度智能云
│   └── factory.py             # 识别服务工厂
├── batch.py                   # 批量识别服务
└── protocol.py                # 统一接口协议
```

## 2. 统一接口协议

### 2.1 请求格式 (RecognizeRequest)

```python
from pydantic import BaseModel
from typing import List, Optional
from enum import Enum

class Platform(str, Enum):
    local = "local"
    huggingface = "huggingface"
    modelscope = "modelscope"
    aliyun = "aliyun"
    baidu = "baidu"
    custom = "custom"

class RecognizeRequest(BaseModel):
    """单张图片识别请求"""
    image_path: str                    # 图片路径 (本地)
    image_url: Optional[str] = None    # 或图片 URL
    image_base64: Optional[str] = None # 或 Base64
    platform: Platform                 # 识别平台
    top_k: int = 5                     # 返回前 K 个结果
    timeout: int = 60                  # 超时时间(秒)

class BatchRecognizeRequest(BaseModel):
    """批量识别请求"""
    images: List[RecognizeRequest]
    batch_id: str                      # 批次 ID，用于异步回调
    webhook_url: Optional[str] = None  # 完成后回调地址
```

### 2.2 响应格式 (RecognizeResponse)

```python
class RecognitionResult(BaseModel):
    """单个识别结果"""
    label: str              # 物种名称
    scientific_name: Optional[str] = None  # 学名
    confidence: float       # 置信度 (0-1)
    chinese_name: Optional[str] = None     # 中文名

class RecognizeResponse(BaseModel):
    """识别响应"""
    success: bool
    image_path: str
    results: List[RecognitionResult]
    platform: str
    processing_time_ms: int
    error: Optional[str] = None
```

## 3. 云平台适配器实现

### 3.1 HuggingFace Adapter

```python
# src/recognition/cloud/huggingface.py
import requests
from ...core.io import get_fs_manager

class HuggingFaceRecognizer:
    ENDPOINT = "https://api-inference.huggingface.co/models/{model_id}"

    def __init__(self, model_id: str, api_token: str):
        self.model_id = model_id
        self.headers = {"Authorization": f"Bearer {api_token}"}

    async def recognize(self, image_data: bytes, top_k: int = 5) -> List[RecognitionResult]:
        response = requests.post(
            self.ENDPOINT.format(model_id=self.model_id),
            headers=self.headers,
            data=image_data,
            timeout=60
        )
        response.raise_for_status()
        results = response.json()

        return [
            RecognitionResult(
                label=item["label"],
                confidence=item["score"]
            )
            for item in results[:top_k]
        ]
```

### 3.2 ModelScope Adapter

```python
# src/recognition/cloud/modelscope.py
from modelscope.pipelines import pipeline

class ModelScopeRecognizer:
    def __init__(self, model_id: str, api_token: str):
        self.pipe = pipeline(
            'image-classification',
            model_id,
            api_token=api_token
        )

    async def recognize(self, image_data: bytes, top_k: int = 5) -> List[RecognitionResult]:
        import base64
        from io import BytesIO
        from PIL import Image

        # Base64 转图片
        image = Image.open(BytesIO(image_data))
        results = self.pipe(image, top_k=top_k)

        return [
            RecognitionResult(
                label=item["label"],
                confidence=item["score"]
            )
            for item in results
        ]
```

### 3.3 阿里云 Adapter

```python
# src/recognition/cloud/aliyun.py
from alibabacloud_imagerecog20190930.client import Client
from alibabacloud_imagerecog20190930.models import DetectImageTagsRequest
from alibabacloud_tea_openapi.models import Config

class AliyunRecognizer:
    def __init__(self, access_key_id: str, access_key_secret: str):
        config = Config(
            access_key_id=access_key_id,
            access_key_secret=access_key_secret,
            endpoint='imagerecog.cn-shanghai.aliyuncs.com',
            region_id='cn-shanghai'
        )
        self.client = Client(config)

    async def recognize(self, image_data: bytes, top_k: int = 5) -> List[RecognitionResult]:
        import base64

        request = DetectImageTagsRequest()
        request.image_url = f"data:image/jpeg;base64,{base64.b64encode(image_data).decode()}"

        response = self.client.detect_image_tags_with_options(request)
        results = response.body.data.tags[:top_k]

        return [
            RecognitionResult(
                label=item.label,
                confidence=item.confidence / 100.0  # 阿里云是百分比
            )
            for item in results
        ]
```

### 3.4 工厂模式

```python
# src/recognition/cloud/factory.py
from .huggingface import HuggingFaceRecognizer
from .modelscope import ModelScopeRecognizer
from .aliyun import AliyunRecognizer

class RecognizerFactory:
    _recognizers = {
        "huggingface": HuggingFaceRecognizer,
        "modelscope": ModelScopeRecognizer,
        "aliyun": AliyunRecognizer,
    }

    @classmethod
    def create(cls, platform: str, **config) -> "BaseRecognizer":
        if platform not in cls._recognizers:
            raise ValueError(f"Unknown platform: {platform}")
        return cls._recognizers[platform](**config)
```

## 4. 批量识别 API

### 4.1 REST API 定义

```python
# src/web/routes/recognition.py
from fastapi import APIRouter, BackgroundTasks
from ..schemas import BatchRecognizeRequest, BatchRecognizeResponse
from ...recognition.batch import BatchRecognitionService

router = APIRouter(prefix="/api/recognition", tags=["recognition"])
batch_service = BatchRecognitionService()

@router.post("/recognize")
async def recognize(request: RecognizeRequest) -> RecognizeResponse:
    """单张图片识别"""
    return await batch_service.recognize_single(request)

@router.post("/batch")
async def batch_recognize(
    request: BatchRecognizeRequest,
    background_tasks: BackgroundTasks
) -> BatchRecognizeResponse:
    """批量识别（异步）"""
    return await batch_service.create_batch(request, background_tasks)

@router.get("/batch/{batch_id}")
async def get_batch_result(batch_id: str) -> BatchRecognizeResponse:
    """查询批量任务结果"""
    return await batch_service.get_batch_result(batch_id)

@router.get("/batch/{batch_id}/status")
async def get_batch_status(batch_id: str) -> dict:
    """查询批量任务状态"""
    return await batch_service.get_batch_status(batch_id)
```

### 4.2 批量服务实现

```python
# src/recognition/batch.py
import asyncio
from typing import Dict, List
from ..schemas import BatchRecognizeRequest, RecognizeResponse
from .cloud.factory import RecognizerFactory

class BatchRecognitionService:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.batches: Dict[str, BatchJob] = {}

    async def recognize_single(self, request: RecognizeRequest) -> RecognizeResponse:
        recognizer = RecognizerFactory.create(
            request.platform.value,
            **self._get_credentials(request.platform.value)
        )

        # 获取图片数据
        fs = get_fs_manager()
        image_data = await fs.read_bytes(request.image_path)

        # 识别
        start_time = time.time()
        results = await recognizer.recognize(image_data, request.top_k)
        processing_time = int((time.time() - start_time) * 1000)

        # 映射到鸟类数据库
        mapped_results = await self._map_to_bird_species(results)

        return RecognizeResponse(
            success=True,
            image_path=request.image_path,
            results=mapped_results,
            platform=request.platform.value,
            processing_time_ms=processing_time
        )

    async def create_batch(
        self,
        request: BatchRecognizeRequest,
        background_tasks: BackgroundTasks
    ) -> BatchRecognizeResponse:
        batch_id = generate_batch_id()
        self.batches[batch_id] = BatchJob(
            id=batch_id,
            images=request.images,
            status="processing",
            results=[]
        )

        background_tasks.add_task(self._process_batch, batch_id)

        return BatchRecognizeResponse(
            batch_id=batch_id,
            total=len(request.images),
            status="processing"
        )

    async def _process_batch(self, batch_id: str):
        job = self.batches[batch_id]

        for request in job.images:
            try:
                result = await self.recognize_single(request)
                job.results.append(result)
            except Exception as e:
                job.results.append(create_error_response(request, str(e)))

        job.status = "completed"
        job.completed_at = datetime.now()

        # 如果有 webhook，触发回调
        if job.webhook_url:
            await self._trigger_webhook(job)
```

## 5. 认证机制设计

### 5.1 API Key 认证

```python
# src/web/auth/api_key.py
from fastapi import Security, HTTPException, status
from fastapi.security import APIKeyHeader
from typing import Optional

api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)) -> str:
    """验证 API Key"""
    # 从数据库查询有效的 API Key
    valid_key = await get_valid_api_key(api_key)
    if not valid_key:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid or expired API key"
        )
    return valid_key.user_id

class APIKeyManager:
    """API Key 管理"""

    async def create_key(self, user_id: str, name: str) -> str:
        """创建新的 API Key"""
        key = f"ft_{secrets.token_hex(16)}"
        await self._save_key(user_id, key, name)
        return key

    async def revoke_key(self, key: str):
        """撤销 API Key"""
        await self._update_key_status(key, "revoked")

    async def get_usage(self, key: str) -> dict:
        """获取 API 使用量"""
        return await self._get_usage_stats(key)
```

### 5.2 配置 secrets.yaml

```yaml
# config/secrets.yaml

# 本地识别（保留）
local:
  enabled: true

# 云平台认证
cloud:
  huggingface:
    api_token: ${HF_TOKEN}          # 环境变量或直接填入
    model_id: microsoft/BioCLIP     # 可选，自定义模型

  modelscope:
    api_token: ${MODELSCOPE_TOKEN}
    model_id: damo/cv_resnet50_image-classification_birds

  aliyun:
    access_key_id: ${ALIYUN_ACCESS_KEY_ID}
    access_key_secret: ${ALIYUN_ACCESS_KEY_SECRET}

  baidu:
    api_key: ${BAIDU_API_KEY}
    secret_key: ${BAIDU_SECRET_KEY}

# API 认证
api_keys:
  - name: "default"
    key: ${FEATHERTRACE_API_KEY}    # 主 API Key
    rate_limit: 1000/day
    quota: 10000/month
```

### 5.3 Web 认证中间件

```python
# src/web/middleware/auth.py
from fastapi import Depends
from .api_key import verify_api_key

# 需要认证的路由
@router.post("/batch", dependencies=[Depends(verify_api_key)])
async def batch_recognize(...):
    ...

# 可选认证的路由
@router.get("/platforms")
async def list_platforms(api_key: str = Security(verify_api_key, optional=True)):
    """列出可用的识别平台（无需认证）"""
    return {"platforms": ["local", "huggingface", "modelscope", "aliyun"]}
```

## 6. 部署方案

### 6.1 分离部署架构

```
┌────────────────────────────────────────────────────────────┐
│                     本地 FeatherTrace                       │
│  ┌─────────────────┐  ┌─────────────────────────────────┐  │
│  │  Web UI :8000   │  │  Pipeline                       │  │
│  │                 │  │  ├── SmartScanner               │  │
│  │  API Routes     │  │  ├── YOLO Detection             │  │
│  │  └── batch API  │──┼─►│  └── HTTP Request ───────────┼──┼──►  │
│  └─────────────────┘  └─────────────────────────────────┘  │    │
│                                                              │    │  ┌─────────────────────────┐
│                                                              └──►│  │ 识别服务 (独立部署)      │
│                                                                   │  │  :8080                   │
│  ┌───────────────────────────────────────────────────────────┐  │  │  ├── /api/recognize      │
│  │  docker-compose.remote.yml                                │  │  │  └── /api/batch         │
│  │  - recognition-service (CPU/GPU)                          │  │  └─────────────────────────┘
│  │  - redis (可选，批量任务队列)                              │  │
│  └───────────────────────────────────────────────────────────┘  │
└────────────────────────────────────────────────────────────┘
```

### 6.2 Docker Compose 配置

```yaml
# docker-compose.remote.yml
version: '3.8'

services:
  # 识别服务 (CPU 版本)
  recognition-cpu:
    build:
      context: .
      dockerfile: Dockerfile.recognition.cpu
    ports:
      - "8080:8000"
    environment:
      - PLATFORM=local
      - CUDA_VISIBLE_DEVICES=  # 留空，强制使用 CPU
      - LOG_LEVEL=INFO
    volumes:
      - ./config:/app/config
      - ./models:/app/models
      - ./data:/app/data

  # 识别服务 (GPU 版本)
  recognition-gpu:
    build:
      context: .
      dockerfile: Dockerfile.recognition.gpu
    ports:
      - "8081:8000"
    environment:
      - PLATFORM=local
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 消息队列 (可选，用于大批量处理)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

### 6.3 Dockerfile

```dockerfile
# Dockerfile.recognition.cpu
FROM python:3.10-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y --no-install-recommends \
    exiftool \
    && rm -rf /var/lib/apt/lists/*

# 安装 Python 依赖
COPY requirements*.txt ./
RUN pip install --no-cache-dir -r requirements-cpu.txt

# 复制代码
COPY . .

# 下载模型 (可选)
# RUN python scripts/download_model.py

EXPOSE 8000

CMD ["uvicorn", "src.recognition_service:app", "--host", "0.0.0.0", "--port", "8000"]
```

```dockerfile
# Dockerfile.recognition.gpu
FROM nvidia/cuda:12.1-cudnn8-runtime-ubuntu22.04

WORKDIR /app

# 安装系统依赖和 PyTorch GPU 版本
RUN apt-get update && apt-get install -y --no-install-recommends \
    exiftool \
    && rm -rf /var/lib/apt/lists/*

COPY requirements*.txt ./
RUN pip install --no-cache-dir -r requirements-gpu.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "src.recognition_service:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 6.4 一键部署脚本

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

MODE=${1:-"all"}  # all, local, remote, gpu, cpu

case $MODE in
    "local")
        # 本地一体化部署
        docker-compose up -d
        ;;
    "cpu")
        # 仅 CPU 识别服务
        docker-compose -f docker-compose.remote.yml up -d recognition-cpu
        ;;
    "gpu")
        # 仅 GPU 识别服务
        docker-compose -f docker-compose.remote.yml up -d recognition-gpu
        ;;
    "all")
        # 完整分离部署
        docker-compose -f docker-compose.yml -f docker-compose.remote.yml up -d
        ;;
    *)
        echo "Usage: $0 [local|cpu|gpu|all]"
        exit 1
        ;;
esac

echo "Deployment complete!"
echo "Web UI: http://localhost:8000"
echo "Recognition API: http://localhost:8080"
```

## 7. 兼容性与映射

### 7.1 平台能力矩阵

| 功能 | Local | HuggingFace | ModelScope | Aliyun | Baidu |
|------|-------|-------------|------------|--------|-------|
| 单张识别 | ✓ | ✓ | ✓ | ✓ | ✓ |
| 批量识别 | ✓ | ✓ | ✓ | ✓ | ✓ |
| 置信度 | ✓ | ✓ | ✓ | ✓ | ✓ |
| 学名映射 | ✓ | ✓ | ✓ | ✗ | ✗ |
| 中文名映射 | ✓ | ✓ | ✓ | ✓ | ✓ |
| 实时流 | ✓ | ✗ | ✗ | ✗ | ✗ |

### 7.2 物种名称映射

```python
async def _map_to_bird_species(self, results: List[RecognitionResult]) -> List[RecognitionResult]:
    """将云平台返回的标签映射到 IOC 鸟类数据库"""

    # 加载 IOC 数据库
    ioc_manager = get_ioc_manager()

    mapped = []
    for result in results:
        # 模糊匹配
        species = await ioc_manager.find_species(
            query=result.label,
            fuzzy=True
        )

        if species:
            result.scientific_name = species.scientific_name
            result.chinese_name = species.chinese_name
            result.source_label = result.label  # 保留原始标签
        mapped.append(result)

    return mapped
```

## 8. 实施计划

### Phase 1: 基础架构 (2-3 天)
- [ ] 定义统一接口协议 `protocol.py`
- [ ] 实现云平台抽象基类
- [ ] 实现 HuggingFace 适配器（作为第一个示例）

### Phase 2: 云平台适配 (3-5 天)
- [ ] 实现 ModelScope 适配器
- [ ] 实现阿里云适配器
- [ ] 实现百度云适配器
- [ ] 添加 API Key 认证机制

### Phase 3: 批量 API (2-3 天)
- [ ] 实现 `BatchRecognitionService`
- [ ] 添加 REST API 端点
- [ ] 添加 WebSocket 实时进度

### Phase 4: 部署支持 (2-3 天)
- [ ] 编写 Dockerfile (CPU/GPU)
- [ ] 编写 docker-compose 配置
- [ ] 更新一键部署脚本
- [ ] 编写部署文档

## 9. 参考资料

- [HuggingFace Inference API](https://huggingface.co/docs/inference/api)
- [魔搭社区 API-Inference](https://modelscope.cn/docs/model-service/API-Inference/intro)
- [阿里云视觉智能 SDK](https://help.aliyun.com/zh/viapi/developer-reference/python)
- [FastAPI Batch Processing Best Practices](https://fastapi.tiangolo.com/advanced/background-tasks/)
